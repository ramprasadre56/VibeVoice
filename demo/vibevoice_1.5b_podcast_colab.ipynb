{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# üéôÔ∏è VibeVoice Podcast Generation Server\n",
                "\n",
                "This notebook runs the VibeVoice Realtime-0.5B model for podcast generation.\n",
                "\n",
                "**Requirements:**\n",
                "- GPU runtime (T4 or better)\n",
                "- ~8GB GPU memory\n",
                "\n",
                "**Usage:**\n",
                "1. Run all cells in order\n",
                "2. Copy the public URL from Cell 6"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install"
            },
            "outputs": [],
            "source": [
                "#@title 1Ô∏è‚É£ Install Dependencies (exact versions required)\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# CRITICAL: Install exact transformers version required by VibeVoice\n",
                "!pip install -q transformers==4.51.3 accelerate==1.6.0\n",
                "!pip install -q torch torchaudio diffusers fastapi uvicorn scipy\n",
                "\n",
                "# Clone the VibeVoice repo\n",
                "if not os.path.exists('/content/VibeVoice'):\n",
                "    !git clone --depth 1 https://github.com/microsoft/VibeVoice.git /content/VibeVoice\n",
                "    print(\"‚úÖ Cloned VibeVoice repo\")\n",
                "else:\n",
                "    print(\"‚úÖ VibeVoice repo already exists\")\n",
                "\n",
                "# Add repo to Python path\n",
                "sys.path.insert(0, '/content/VibeVoice')\n",
                "\n",
                "# Verify import works\n",
                "try:\n",
                "    import transformers\n",
                "    print(f\"‚úÖ Transformers version: {transformers.__version__}\")\n",
                "    from vibevoice.modular.modeling_vibevoice_streaming_inference import VibeVoiceStreamingForConditionalGenerationInference\n",
                "    print(\"‚úÖ VibeVoice module found!\")\n",
                "except ImportError as e:\n",
                "    print(f\"‚ö†Ô∏è Import failed: {e}\")\n",
                "    print(\"Running pip install for VibeVoice...\")\n",
                "    !pip install -q /content/VibeVoice"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "check_gpu"
            },
            "outputs": [],
            "source": [
                "#@title 2Ô∏è‚É£ Check GPU & Setup Path\n",
                "import sys\n",
                "import torch\n",
                "\n",
                "if '/content/VibeVoice' not in sys.path:\n",
                "    sys.path.insert(0, '/content/VibeVoice')\n",
                "\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No GPU! Go to: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "load_model"
            },
            "outputs": [],
            "source": [
                "#@title 3Ô∏è‚É£ Load VibeVoice Model\n",
                "import torch\n",
                "import copy\n",
                "import sys\n",
                "\n",
                "if '/content/VibeVoice' not in sys.path:\n",
                "    sys.path.insert(0, '/content/VibeVoice')\n",
                "\n",
                "from vibevoice.modular.modeling_vibevoice_streaming_inference import VibeVoiceStreamingForConditionalGenerationInference\n",
                "from vibevoice.processor.vibevoice_streaming_processor import VibeVoiceStreamingProcessor\n",
                "\n",
                "MODEL_PATH = \"microsoft/VibeVoice-Realtime-0.5B\"\n",
                "\n",
                "print(\"Loading processor...\")\n",
                "processor = VibeVoiceStreamingProcessor.from_pretrained(MODEL_PATH)\n",
                "\n",
                "print(\"Loading model (2-3 minutes)...\")\n",
                "try:\n",
                "    model = VibeVoiceStreamingForConditionalGenerationInference.from_pretrained(\n",
                "        MODEL_PATH,\n",
                "        torch_dtype=torch.bfloat16,\n",
                "        device_map=\"cuda\",\n",
                "        attn_implementation=\"flash_attention_2\"\n",
                "    )\n",
                "    print(\"Using Flash Attention 2\")\n",
                "except:\n",
                "    print(\"Flash attention not available, using sdpa...\")\n",
                "    model = VibeVoiceStreamingForConditionalGenerationInference.from_pretrained(\n",
                "        MODEL_PATH,\n",
                "        torch_dtype=torch.bfloat16,\n",
                "        device_map=\"cuda\",\n",
                "        attn_implementation=\"sdpa\"\n",
                "    )\n",
                "    \n",
                "model.eval()\n",
                "model.set_ddpm_inference_steps(num_steps=5)\n",
                "print(\"‚úÖ Model loaded successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "load_voices"
            },
            "outputs": [],
            "source": [
                "#@title 4Ô∏è‚É£ Load Voice Presets\n",
                "import torch\n",
                "from pathlib import Path\n",
                "\n",
                "VOICES_DIR = Path(\"/content/VibeVoice/demo/voices/streaming_model\")\n",
                "\n",
                "voice_presets = {}\n",
                "\n",
                "if VOICES_DIR.exists():\n",
                "    print(f\"Loading voices from: {VOICES_DIR}\")\n",
                "    for voice_file in sorted(VOICES_DIR.glob(\"en-*.pt\")):\n",
                "        name = voice_file.stem\n",
                "        try:\n",
                "            voice_presets[name] = torch.load(voice_file, map_location=\"cuda\", weights_only=False)\n",
                "            print(f\"  ‚úÖ {name}\")\n",
                "        except Exception as e:\n",
                "            print(f\"  ‚ö†Ô∏è {name}: {e}\")\n",
                "else:\n",
                "    print(f\"‚ùå Voices directory not found: {VOICES_DIR}\")\n",
                "\n",
                "if voice_presets:\n",
                "    print(f\"\\n‚úÖ Loaded {len(voice_presets)} voices!\")\n",
                "else:\n",
                "    print(\"\\n‚ö†Ô∏è No voices loaded - will use default\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "create_server"
            },
            "outputs": [],
            "source": [
                "#@title 5Ô∏è‚É£ Create FastAPI Server\n",
                "from fastapi import FastAPI, HTTPException\n",
                "from fastapi.responses import FileResponse\n",
                "from fastapi.middleware.cors import CORSMiddleware\n",
                "from pydantic import BaseModel\n",
                "from typing import Optional\n",
                "import uuid\n",
                "import scipy.io.wavfile as wavfile\n",
                "import numpy as np\n",
                "import re\n",
                "\n",
                "app = FastAPI(title=\"VibeVoice Podcast API\")\n",
                "\n",
                "app.add_middleware(\n",
                "    CORSMiddleware,\n",
                "    allow_origins=[\"*\"],\n",
                "    allow_credentials=True,\n",
                "    allow_methods=[\"*\"],\n",
                "    allow_headers=[\"*\"],\n",
                ")\n",
                "\n",
                "class PodcastRequest(BaseModel):\n",
                "    script: str\n",
                "    title: Optional[str] = \"podcast\"\n",
                "    speaker1_voice: Optional[str] = \"en-Carter_man\"\n",
                "    speaker2_voice: Optional[str] = \"en-Emma_woman\"\n",
                "\n",
                "@app.get(\"/\")\n",
                "def root():\n",
                "    return {\"status\": \"ok\", \"model\": \"VibeVoice-Realtime-0.5B\", \"type\": \"podcast\"}\n",
                "\n",
                "@app.get(\"/health\")\n",
                "def health():\n",
                "    return {\"status\": \"healthy\"}\n",
                "\n",
                "@app.get(\"/config\")\n",
                "def config():\n",
                "    return {\n",
                "        \"voices\": list(voice_presets.keys()) if voice_presets else [\"default\"],\n",
                "        \"default_voice\": list(voice_presets.keys())[0] if voice_presets else \"default\"\n",
                "    }\n",
                "\n",
                "def parse_script(script: str):\n",
                "    lines = script.strip().split(\"\\n\")\n",
                "    parsed = []\n",
                "    for line in lines:\n",
                "        if not line.strip():\n",
                "            continue\n",
                "        match = re.match(r'^Speaker\\s+(\\d+)\\s*:\\s*(.*)$', line.strip(), re.IGNORECASE)\n",
                "        if match:\n",
                "            speaker_id = int(match.group(1))\n",
                "            text = match.group(2).strip()\n",
                "            if text:\n",
                "                parsed.append((speaker_id, text))\n",
                "    return parsed\n",
                "\n",
                "def generate_speech(text: str, voice_name: str):\n",
                "    voice = None\n",
                "    if voice_presets:\n",
                "        voice = voice_presets.get(voice_name, list(voice_presets.values())[0])\n",
                "    \n",
                "    if voice:\n",
                "        inputs = processor.process_input_with_cached_prompt(\n",
                "            text=text,\n",
                "            cached_prompt=voice,\n",
                "            padding=True,\n",
                "            return_tensors=\"pt\",\n",
                "            return_attention_mask=True,\n",
                "        )\n",
                "    else:\n",
                "        inputs = processor(\n",
                "            text=text,\n",
                "            padding=True,\n",
                "            return_tensors=\"pt\",\n",
                "            return_attention_mask=True,\n",
                "        )\n",
                "    \n",
                "    for k, v in inputs.items():\n",
                "        if torch.is_tensor(v):\n",
                "            inputs[k] = v.to(\"cuda\")\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model.generate(\n",
                "            **inputs,\n",
                "            max_new_tokens=None,\n",
                "            cfg_scale=1.5,\n",
                "            tokenizer=processor.tokenizer,\n",
                "            generation_config={'do_sample': False},\n",
                "            verbose=False,\n",
                "            all_prefilled_outputs=copy.deepcopy(voice) if voice else None,\n",
                "        )\n",
                "    \n",
                "    # Convert bfloat16 to float32 and flatten to 1D\n",
                "    audio = outputs.speech_outputs[0].cpu().float().numpy()\n",
                "    return audio.flatten()\n",
                "\n",
                "@app.post(\"/generate-podcast\")\n",
                "async def generate_podcast(request: PodcastRequest):\n",
                "    try:\n",
                "        print(f\"\\nüéôÔ∏è Generating podcast ({len(request.script)} chars)...\")\n",
                "        \n",
                "        segments = parse_script(request.script)\n",
                "        if not segments:\n",
                "            raise HTTPException(400, \"No valid speaker lines. Use: Speaker 1: text\")\n",
                "        \n",
                "        print(f\"üìù Found {len(segments)} segments\")\n",
                "        \n",
                "        voice_map = {1: request.speaker1_voice, 2: request.speaker2_voice}\n",
                "        \n",
                "        audio_segments = []\n",
                "        for i, (speaker_id, text) in enumerate(segments):\n",
                "            voice = voice_map.get(speaker_id, request.speaker1_voice)\n",
                "            print(f\"  [{i+1}/{len(segments)}] Speaker {speaker_id} ({voice}): {text[:40]}...\")\n",
                "            audio = generate_speech(text, voice)\n",
                "            audio_segments.append(audio)\n",
                "            # Add pause between segments (0.3s at 24kHz)\n",
                "            audio_segments.append(np.zeros(int(24000 * 0.3), dtype=np.float32))\n",
                "        \n",
                "        full_audio = np.concatenate(audio_segments)\n",
                "        \n",
                "        # Normalize and convert to int16\n",
                "        max_val = np.max(np.abs(full_audio))\n",
                "        if max_val > 0:\n",
                "            full_audio = full_audio / max_val\n",
                "        full_audio = (full_audio * 32767).astype(np.int16)\n",
                "        \n",
                "        output_id = str(uuid.uuid4())[:8]\n",
                "        output_path = f\"/tmp/{request.title}_{output_id}.wav\"\n",
                "        wavfile.write(output_path, 24000, full_audio)\n",
                "        \n",
                "        print(f\"‚úÖ Generated: {output_path} ({len(full_audio)/24000:.1f}s)\")\n",
                "        \n",
                "        return FileResponse(output_path, media_type=\"audio/wav\", filename=f\"{request.title}.wav\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        import traceback\n",
                "        traceback.print_exc()\n",
                "        raise HTTPException(500, str(e))\n",
                "\n",
                "print(\"‚úÖ FastAPI server created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "start_server"
            },
            "outputs": [],
            "source": [
                "#@title 6Ô∏è‚É£ Start Server with Public URL\n",
                "import subprocess\n",
                "import threading\n",
                "import time\n",
                "import re\n",
                "\n",
                "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /tmp/cloudflared\n",
                "!chmod +x /tmp/cloudflared\n",
                "\n",
                "PORT = 8000\n",
                "\n",
                "def run_uvicorn():\n",
                "    import uvicorn\n",
                "    uvicorn.run(app, host=\"0.0.0.0\", port=PORT, log_level=\"warning\")\n",
                "\n",
                "server_thread = threading.Thread(target=run_uvicorn, daemon=True)\n",
                "server_thread.start()\n",
                "time.sleep(3)\n",
                "\n",
                "print(\"\\nüîó Starting Cloudflare tunnel...\\n\")\n",
                "process = subprocess.Popen(\n",
                "    [\"/tmp/cloudflared\", \"tunnel\", \"--url\", f\"http://localhost:{PORT}\"],\n",
                "    stdout=subprocess.PIPE,\n",
                "    stderr=subprocess.STDOUT,\n",
                "    text=True\n",
                ")\n",
                "\n",
                "for line in process.stdout:\n",
                "    match = re.search(r'https://[\\w-]+\\.trycloudflare\\.com', line)\n",
                "    if match:\n",
                "        public_url = match.group(0)\n",
                "        print(\"=\"*60)\n",
                "        print(\"üéôÔ∏è VibeVoice Podcast Server is ready!\")\n",
                "        print(\"=\"*60)\n",
                "        print(f\"\\nüì° PUBLIC URL: {public_url}\")\n",
                "        print(f\"\\nüëÜ Copy this to your web app Settings!\")\n",
                "        print(\"\\n\" + \"=\"*60)\n",
                "        break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "test"
            },
            "outputs": [],
            "source": [
                "#@title 7Ô∏è‚É£ Test: Generate Sample Podcast\n",
                "import requests\n",
                "from IPython.display import Audio\n",
                "\n",
                "test_script = \"\"\"Speaker 1: Welcome! Today we're learning about text to speech.\n",
                "Speaker 2: That sounds interesting! How does it work?\n",
                "Speaker 1: AI models convert written text into natural sounding speech.\n",
                "Speaker 2: Wow, that's amazing technology!\"\"\"\n",
                "\n",
                "print(\"Generating test podcast...\")\n",
                "response = requests.post(\n",
                "    f\"http://localhost:{PORT}/generate-podcast\",\n",
                "    json={\"script\": test_script, \"title\": \"test\", \"speaker1_voice\": \"en-Carter_man\", \"speaker2_voice\": \"en-Emma_woman\"}\n",
                ")\n",
                "\n",
                "if response.status_code == 200:\n",
                "    with open(\"/tmp/test.wav\", \"wb\") as f:\n",
                "        f.write(response.content)\n",
                "    print(\"‚úÖ Success!\")\n",
                "    Audio(\"/tmp/test.wav\")\n",
                "else:\n",
                "    print(f\"‚ùå Error: {response.text}\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}